{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **FLOPs For IRv2**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, concatenate, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, Dropout, UpSampling2D, ZeroPadding2D\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom skimage.transform import resize\nimport os\nimport csv\nimport PIL\nimport numpy as np\nimport random\nimport cv2\n# import imutils\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\nfrom tensorflow.keras.applications import InceptionResNetV2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:55:54.861138Z","iopub.execute_input":"2025-01-12T19:55:54.861338Z","iopub.status.idle":"2025-01-12T19:56:04.600066Z","shell.execute_reply.started":"2025-01-12T19:55:54.861321Z","shell.execute_reply":"2025-01-12T19:56:04.599289Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"HEIGHT = 240\nWIDTH = 320\nINIT_LR = 0.0001\nEPOCHS = 15\nTRAIN_PATH = \"/kaggle/input/cityscape-csv/cityscape_train.csv\"\nTEST_PATH = \"/kaggle/input/cityscape-csv/cityscape_test.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:56:04.601171Z","iopub.execute_input":"2025-01-12T19:56:04.601707Z","iopub.status.idle":"2025-01-12T19:56:04.605437Z","shell.execute_reply.started":"2025-01-12T19:56:04.601682Z","shell.execute_reply":"2025-01-12T19:56:04.604598Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def downsampling_block(input_tensor, n_filters):\n  x = Conv2D(filters=n_filters, kernel_size=(3,3), padding='same')(input_tensor)\n  x = LeakyReLU(alpha=0.2)(x)\n  x = BatchNormalization()(x)\n\n  x = Conv2D(filters=n_filters, kernel_size=(3,3), padding='same')(x)\n  x = LeakyReLU(alpha=0.2)(x)\n  x = BatchNormalization()(x)\n  return x\n\ndef upsampling_block(input_tensor, n_filters, name, concat_with):\n  x = UpSampling2D((2, 2), interpolation='bilinear', name=name)(input_tensor)\n  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+\"_convA\")(x)\n  x = LeakyReLU(alpha=0.2)(x)\n\n  x = concatenate([x, concat_with], axis=3)\n\n  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+\"_convB\")(x)\n  x = LeakyReLU(alpha=0.2)(x)\n  x = BatchNormalization()(x)\n\n  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+\"_convC\")(x)\n  x = LeakyReLU(alpha=0.2)(x)\n  x = BatchNormalization()(x)\n  return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:56:04.607050Z","iopub.execute_input":"2025-01-12T19:56:04.607265Z","iopub.status.idle":"2025-01-12T19:56:04.623505Z","shell.execute_reply.started":"2025-01-12T19:56:04.607247Z","shell.execute_reply":"2025-01-12T19:56:04.622855Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\ndef build(height, width, depth):\n  # input\n  i = Input(shape=(height, width, depth))\n\n  iresnet = InceptionResNetV2(include_top = False, weights = \"imagenet\", input_tensor = i)\n  # iresnet.summary()\n\n\n  conv1 = iresnet.get_layer(\"input_layer\").output\n  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n  conv2 = iresnet.get_layer(\"activation\").output\n  conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)  \n  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n  conv3 = iresnet.get_layer(\"activation_3\").output\n  conv3 = ZeroPadding2D((1,1))(conv3)  \n  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n  conv4 = iresnet.get_layer(\"activation_74\").output\n  conv4 = ZeroPadding2D(((2,1),(2,1)))(conv4)  \n  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n  \n\n  # bottleneck\n#   conv5 = Conv2D(512, (3, 3), padding='same')(pool4)\n  conv5 = iresnet.get_layer(\"activation_161\").output\n  conv5 = ZeroPadding2D((1,1))(conv5) \n  conv5 = LeakyReLU(alpha=0.2)(conv5)\n#   conv5 = Conv2D(512, (3, 3), padding='same')(conv5)\n  conv5 = iresnet.get_layer(\"activation_161\").output\n  conv5 = ZeroPadding2D((1,1))(conv5)\n  conv5 = LeakyReLU(alpha=0.2)(conv5)\n\n  print(conv5.shape,conv4.shape)\n\n  # decoder\n  conv6 = upsampling_block(conv5, 256, \"up1\", concat_with=conv4)\n  conv7 = upsampling_block(conv6, 128, \"up2\", concat_with=conv3)\n  conv8 = upsampling_block(conv7, 64, \"up3\", concat_with=conv2)\n  conv9 = upsampling_block(conv8, 32, \"up4\", concat_with=conv1)\n\n  # output\n  o = Conv2D(filters=1, kernel_size=3, strides=(1,1), activation='sigmoid', padding='same', name='conv10')(conv9)\n\n  model = Model(inputs=i, outputs=o)\n  return model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:56:04.624890Z","iopub.execute_input":"2025-01-12T19:56:04.625201Z","iopub.status.idle":"2025-01-12T19:56:04.641541Z","shell.execute_reply.started":"2025-01-12T19:56:04.625155Z","shell.execute_reply":"2025-01-12T19:56:04.640934Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = build(HEIGHT, WIDTH, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:56:04.642245Z","iopub.execute_input":"2025-01-12T19:56:04.642516Z","iopub.status.idle":"2025-01-12T19:56:11.024687Z","shell.execute_reply.started":"2025-01-12T19:56:04.642495Z","shell.execute_reply":"2025-01-12T19:56:11.023657Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n(None, 15, 20, 288) (None, 30, 40, 256)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:56:11.025416Z","iopub.execute_input":"2025-01-12T19:56:11.025621Z","iopub.status.idle":"2025-01-12T19:56:11.029051Z","shell.execute_reply.started":"2025-01-12T19:56:11.025602Z","shell.execute_reply":"2025-01-12T19:56:11.028215Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nparameters = model.count_params()\n\n# Manual FLOPs Calculation for Conv2D and Dense Layers\ndef calculate_flops(model, input_shape=(240, 320, 3)):\n    flops = 0\n\n    # Get input size\n    h, w, c_in = input_shape\n    input_size = h * w * c_in\n    \n    # Calculate FLOPs for Conv2D layers\n    for layer in model.layers:\n        if isinstance(layer, layers.Conv2D):\n            kernel_h, kernel_w = layer.kernel_size\n            c_out = layer.filters\n            stride = layer.strides[0]\n            \n            # Output dimensions after stride\n            output_h = (h - kernel_h) // stride + 1\n            output_w = (w - kernel_w) // stride + 1\n            \n            # FLOPs for Conv2D: Output size * kernel size * input channels * output channels\n            flops += output_h * output_w * c_out * kernel_h * kernel_w * c_in\n            # Update the input dimensions for the next layer\n            h, w, c_in = output_h, output_w, c_out\n    \n    # Calculate FLOPs for Dense layers\n    for layer in model.layers:\n        if isinstance(layer, layers.Dense):\n            # Use layer.input_shape from the model to calculate input units\n            input_units = layer.input.shape[1]  # Input dimension to the Dense layer\n            output_units = layer.units           # Output dimension from the Dense layer\n            \n            # FLOPs for Dense: 2 * input_units * output_units (multiply + add operations)\n            flops += 2 * input_units * output_units\n\n    return flops\n\n# Calculate FLOPs\nflops = calculate_flops(model)\n\n# Print results\nprint(f\"Parameters: {parameters}\")\nprint(f\"FLOPs: {flops}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T19:56:11.029713Z","iopub.execute_input":"2025-01-12T19:56:11.029900Z","iopub.status.idle":"2025-01-12T19:56:11.113260Z","shell.execute_reply.started":"2025-01-12T19:56:11.029883Z","shell.execute_reply":"2025-01-12T19:56:11.112516Z"}},"outputs":[{"name":"stdout","text":"Parameters: 31159265\nFLOPs: 113231474784\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}